{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DrainageAI Demo - Google Colab Integration with BYOL (Unlabeled Data Focus)\n",
    "\n",
    "This notebook demonstrates the DrainageAI workflow using Google Colab's GPU acceleration, focusing on the BYOL approach with unlabeled data only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU detected. Processing will be slow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rasterio geopandas scikit-image matplotlib pytorch-lightning torch-geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Clone the DrainageAI Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/yourusername/DrainageAI.git\n",
    "\n",
    "%cd DrainageAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Upload Test Imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"Please upload your multispectral imagery file (GeoTIFF format):\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Get the filename of the uploaded file\n",
    "imagery_filename = list(uploaded.keys())[0]\n",
    "print(f\"Uploaded file: {imagery_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create Output Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p colab_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Calculate Spectral Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Step 1: Calculate Spectral Indices ===\\n\")\n",
    "\n",
    "!python main.py indices --imagery {imagery_filename} --output colab_results/indices.tif --indices ndvi,ndmi,msavi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Run Drainage Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Step 2: Detect Drainage Pipes ===\\n\")\n",
    "\n",
    "# Choose one of the following model options:\n",
    "\n",
    "# Semi-supervised model (default)\n",
    "!python main.py detect --imagery {imagery_filename} --indices colab_results/indices.tif --output colab_results/drainage_semi.tif --model semi\n",
    "\n",
    "# Uncomment to use BYOL model (new)\n",
    "# !python main.py detect --imagery {imagery_filename} --indices colab_results/indices.tif --output colab_results/drainage_byol.tif --model byol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Vectorize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Step 3: Vectorize Results ===\\n\")\n",
    "\n",
    "# Change the input file if you used a different model\n",
    "detection_file = \"colab_results/drainage_semi.tif\"\n",
    "\n",
    "!python main.py vectorize --input {detection_file} --output colab_results/drainage_lines.shp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BYOL Workflow for Unlabeled Data\n",
    "\n",
    "This section demonstrates the BYOL (Bootstrap Your Own Latent) approach using only unlabeled data for pretraining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Unlabeled Data and Check Image Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for unlabeled data\n",
    "!mkdir -p data/unlabeled/imagery\n",
    "\n",
    "# Upload unlabeled imagery (you can upload multiple files)\n",
    "print(\"Please upload unlabeled imagery files (GeoTIFF format):\")\n",
    "uploaded_unlabeled = files.upload()\n",
    "\n",
    "# Save uploaded files to the unlabeled directory\n",
    "for filename in uploaded_unlabeled.keys():\n",
    "    with open(f\"data/unlabeled/imagery/{filename}\", 'wb') as f:\n",
    "        f.write(uploaded_unlabeled[filename])\n",
    "    print(f\"Saved {filename} to data/unlabeled/imagery/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Image Channels and Convert if Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Create directory for RGB images if needed\n",
    "!mkdir -p data/unlabeled_rgb\n",
    "\n",
    "# Function to convert grayscale to RGB\n",
    "def convert_grayscale_to_rgb(input_path, output_path):\n",
    "    with rasterio.open(input_path) as src:\n",
    "        # Read the data\n",
    "        data = src.read()\n",
    "        profile = src.profile.copy()\n",
    "        \n",
    "        # Check if it's already multi-channel\n",
    "        if data.shape[0] >= 3:\n",
    "            print(f\"Image {input_path} already has {data.shape[0]} channels, skipping.\")\n",
    "            return False\n",
    "        \n",
    "        # Create 3-channel image by duplicating the grayscale channel\n",
    "        if data.shape[0] == 1:\n",
    "            rgb_data = np.repeat(data, 3, axis=0)\n",
    "        else:\n",
    "            # If it has 2 channels, add a third one\n",
    "            zeros = np.zeros_like(data[0:1])\n",
    "            rgb_data = np.concatenate([data, zeros], axis=0)\n",
    "        \n",
    "        # Update profile for RGB output\n",
    "        profile.update(count=3)\n",
    "        \n",
    "        # Write the RGB image\n",
    "        with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "            dst.write(rgb_data)\n",
    "        \n",
    "        return True\n",
    "\n",
    "# Check and convert all images in the unlabeled directory\n",
    "need_conversion = False\n",
    "for filename in os.listdir('data/unlabeled/imagery'):\n",
    "    if filename.endswith(('.tif', '.tiff')):\n",
    "        input_path = os.path.join('data/unlabeled/imagery', filename)\n",
    "        output_path = os.path.join('data/unlabeled_rgb', filename)\n",
    "        \n",
    "        # Check number of channels\n",
    "        with rasterio.open(input_path) as src:\n",
    "            num_channels = src.count\n",
    "            print(f\"Image {filename} has {num_channels} channel(s)\")\n",
    "            \n",
    "            if num_channels < 3:\n",
    "                need_conversion = True\n",
    "                print(f\"Converting {filename} to RGB format...\")\n",
    "                convert_grayscale_to_rgb(input_path, output_path)\n",
    "            else:\n",
    "                print(f\"Image {filename} already has {num_channels} channels, no conversion needed.\")\n",
    "\n",
    "# Determine which directory to use for training\n",
    "if need_conversion:\n",
    "    print(\"\\nUsing converted RGB images for training.\")\n",
    "    optical_dir = \"data/unlabeled_rgb\"\n",
    "else:\n",
    "    print(\"\\nUsing original images for training.\")\n",
    "    optical_dir = \"data/unlabeled/imagery\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BYOL Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== BYOL Pretraining ===\\n\")\n",
    "\n",
    "# Run BYOL pretraining\n",
    "!python examples/byol_mvp_workflow.py \\\n",
    "    --optical-dir {optical_dir} \\\n",
    "    --output-dir colab_results \\\n",
    "    --byol-epochs 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BYOL Inference with Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== BYOL Inference with Pretrained Model ===\\n\")\n",
    "\n",
    "# Run inference with the pretrained BYOL model (without fine-tuning)\n",
    "!python examples/byol_mvp_workflow.py \\\n",
    "    --inference-only \\\n",
    "    --model-path colab_results/byol_pretrained.pth \\\n",
    "    --test-image {imagery_filename} \\\n",
    "    --output-dir colab_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Add Labeled Data for Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Optional: Add Labeled Data for Fine-tuning ===\\n\")\n",
    "print(\"Do you have labeled data for fine-tuning? If yes, upload them now.\")\n",
    "print(\"If not, you can skip this step and use the pretrained model directly.\")\n",
    "\n",
    "use_labeled_data = input(\"Do you have labeled data? (yes/no): \")\n",
    "\n",
    "if use_labeled_data.lower() == 'yes':\n",
    "    # Create directories for labeled data\n",
    "    !mkdir -p data/labeled/imagery\n",
    "    !mkdir -p data/labeled/labels\n",
    "    \n",
    "    # Upload labeled imagery\n",
    "    print(\"\\nPlease upload labeled imagery files (GeoTIFF format):\")\n",
    "    uploaded_labeled_imagery = files.upload()\n",
    "    \n",
    "    # Save uploaded files to the labeled imagery directory\n",
    "    for filename in uploaded_labeled_imagery.keys():\n",
    "        with open(f\"data/labeled/imagery/{filename}\", 'wb') as f:\n",
    "            f.write(uploaded_labeled_imagery[filename])\n",
    "        print(f\"Saved {filename} to data/labeled/imagery/\")\n",
    "    \n",
    "    # Upload label masks\n",
    "    print(\"\\nPlease upload label mask files (GeoTIFF format):\")\n",
    "    uploaded_labels = files.upload()\n",
    "    \n",
    "    # Save uploaded files to the labeled labels directory\n",
    "    for filename in uploaded_labels.keys():\n",
    "        with open(f\"data/labeled/labels/{filename}\", 'wb') as f:\n",
    "            f.write(uploaded_labels[filename])\n",
    "        print(f\"Saved {filename} to data/labeled/labels/\")\n",
    "    \n",
    "    # Check and convert labeled imagery if needed\n",
    "    !mkdir -p data/labeled_rgb\n",
    "    \n",
    "    need_conversion = False\n",
    "    for filename in os.listdir('data/labeled/imagery'):\n",
    "        if filename.endswith(('.tif', '.tiff')):\n",
    "            input_path = os.path.join('data/labeled/imagery', filename)\n",
    "            output_path = os.path.join('data/labeled_rgb', filename)\n",
    "            \n",
    "            # Check number of channels\n",
    "            with rasterio.open(input_path) as src:\n",
    "                num_channels = src.count\n",
    "                print(f\"Image {filename} has {num_channels} channel(s)\")\n",
    "                \n",
    "                if num_channels < 3:\n",
    "                    need_conversion = True\n",
    "                    print(f\"Converting {filename} to RGB format...\")\n",
    "                    convert_grayscale_to_rgb(input_path, output_path)\n",
    "                else:\n",
    "                    print(f\"Image {filename} already has {num_channels} channels, no conversion needed.\")\n",
    "    \n",
    "    # Determine which directory to use for fine-tuning\n",
    "    if need_conversion:\n",
    "        print(\"\\nUsing converted RGB images for fine-tuning.\")\n",
    "        labeled_optical_dir = \"data/labeled_rgb\"\n",
    "    else:\n",
    "        print(\"\\nUsing original images for fine-tuning.\")\n",
    "        labeled_optical_dir = \"data/labeled/imagery\"\n",
    "    \n",
    "    # Run BYOL fine-tuning\n",
    "    print(\"\\n=== BYOL Fine-tuning ===\\n\")\n",
    "    !python examples/byol_mvp_workflow.py \\\n",
    "        --optical-dir {labeled_optical_dir} \\\n",
    "        --label-dir data/labeled/labels \\\n",
    "        --output-dir colab_results \\\n",
    "        --model-path colab_results/byol_pretrained.pth \\\n",
    "        --num-labeled 5 \\\n",
    "        --finetune-epochs 10\n",
    "    \n",
    "    # Run inference with the fine-tuned BYOL model\n",
    "    print(\"\\n=== BYOL Inference with Fine-tuned Model ===\\n\")\n",
    "    !python examples/byol_mvp_workflow.py \\\n",
    "        --inference-only \\\n",
    "        --model-path colab_results/byol_finetuned.pth \\\n",
    "        --test-image {imagery_filename} \\\n",
    "        --output-dir colab_results\n",
    "else:\n",
    "    print(\"Skipping fine-tuning. Using pretrained model for inference.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: SAR Data Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Optional: SAR Data Integration ===\\n\")\n",
    "print(\"Do you have SAR imagery to integrate? If yes, upload it now.\")\n",
    "print(\"If not, you can skip this step.\")\n",
    "\n",
    "use_sar_data = input(\"Do you have SAR data? (yes/no): \")\n",
    "\n",
    "if use_sar_data.lower() == 'yes':\n",
    "    # Upload SAR imagery\n",
    "    print(\"Please upload your SAR imagery file (GeoTIFF format):\")\n",
    "    uploaded_sar = files.upload()\n",
    "    \n",
    "    # Get the filename of the uploaded file\n",
    "    sar_filename = list(uploaded_sar.keys())[0]\n",
    "    print(f\"Uploaded SAR file: {sar_filename}\")\n",
    "    \n",
    "    # Run SAR integration example\n",
    "    print(\"\\n=== SAR Integration ===\\n\")\n",
    "    !python examples/sar_integration_example.py \\\n",
    "        --imagery {imagery_filename} \\\n",
    "        --sar {sar_filename} \\\n",
    "        --output-dir colab_results \\\n",
    "        --visualize\n",
    "    \n",
    "    # Combining BYOL and SAR\n",
    "    print(\"\\n=== BYOL + SAR Integration ===\\n\")\n",
    "    # Use the appropriate model path based on whether fine-tuning was done\n",
    "    model_path = \"colab_results/byol_finetuned.pth\" if use_labeled_data.lower() == 'yes' else \"colab_results/byol_pretrained.pth\"\n",
    "    \n",
    "    !python examples/byol_mvp_workflow.py \\\n",
    "        --inference-only \\\n",
    "        --model-path {model_path} \\\n",
    "        --test-image {imagery_filename} \\\n",
    "        --test-sar {sar_filename} \\\n",
    "        --output-dir colab_results\n",
    "else:\n",
    "    print(\"Skipping SAR integration.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
