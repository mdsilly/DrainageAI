{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DrainageAI Tutorial\n",
    "\n",
    "This notebook demonstrates how to use the DrainageAI system to detect drainage pipes in satellite imagery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary modules and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import geopandas as gpd\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath('__file__'))))\n",
    "\n",
    "from models import EnsembleModel, CNNModel, GNNModel, SelfSupervisedModel\n",
    "from preprocessing import DataLoader, ImageProcessor, GraphBuilder, Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sample Data\n",
    "\n",
    "Next, let's load some sample satellite imagery and elevation data. For this tutorial, you should place sample data in the `data/samples` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define paths to sample data\n",
    "imagery_path = '../data/samples/satellite_imagery.tif'\n",
    "elevation_path = '../data/samples/elevation.tif'\n",
    "\n",
    "# Load imagery\n",
    "with rasterio.open(imagery_path) as src:\n",
    "    imagery = src.read()\n",
    "    imagery_meta = src.meta\n",
    "\n",
    "# Load elevation data\n",
    "with rasterio.open(elevation_path) as src:\n",
    "    elevation = src.read(1)  # Assume single band\n",
    "    elevation_meta = src.meta\n",
    "\n",
    "# Display imagery\n",
    "plt.figure(figsize=(10, 10))\n",
    "show(imagery, transform=imagery_meta['transform'])\n",
    "plt.title('Satellite Imagery')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Display elevation data\n",
    "plt.figure(figsize=(10, 10))\n",
    "show(elevation, transform=elevation_meta['transform'], cmap='terrain')\n",
    "plt.title('Elevation Data')\n",
    "plt.colorbar(label='Elevation (m)')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "\n",
    "Now, let's preprocess the data for input to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create image processor\n",
    "image_processor = ImageProcessor()\n",
    "\n",
    "# Preprocess imagery\n",
    "preprocessed_imagery = image_processor.preprocess(imagery)\n",
    "\n",
    "# Create graph builder\n",
    "graph_builder = GraphBuilder()\n",
    "\n",
    "# Extract node features and positions\n",
    "node_positions, node_features = graph_builder._extract_nodes_from_raster(\n",
    "    imagery, elevation\n",
    ")\n",
    "\n",
    "# Create input data for model\n",
    "input_data = {\n",
    "    'imagery': preprocessed_imagery,\n",
    "    'node_features': node_features,\n",
    "    'node_positions': node_positions,\n",
    "    'elevation': elevation\n",
    "}\n",
    "\n",
    "print(f\"Preprocessed imagery shape: {preprocessed_imagery.shape}\")\n",
    "print(f\"Number of nodes: {len(node_positions)}\")\n",
    "print(f\"Node features shape: {node_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model\n",
    "\n",
    "Next, let's load the DrainageAI model. For this tutorial, we'll use the ensemble model, which combines CNN, GNN, and self-supervised approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create model\n",
    "model = EnsembleModel()\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model created: {type(model).__name__}\")\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference\n",
    "\n",
    "Now, let's run inference on the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run inference\n",
    "with torch.no_grad():\n",
    "    result = model.predict(input_data)\n",
    "\n",
    "# Apply confidence threshold\n",
    "confidence_threshold = 0.5\n",
    "binary_result = (result > confidence_threshold).float()\n",
    "\n",
    "# Convert to numpy array\n",
    "if isinstance(binary_result, torch.Tensor):\n",
    "    binary_result = binary_result.numpy()\n",
    "\n",
    "print(f\"Result shape: {binary_result.shape}\")\n",
    "\n",
    "# Display result\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(binary_result[0], cmap='gray')\n",
    "plt.title('Drainage Detection Result')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "\n",
    "Finally, let's save the results as a GeoTIFF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define output path\n",
    "output_path = '../data/results/drainage_detection.tif'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "# Save as GeoTIFF\n",
    "with rasterio.open(\n",
    "    output_path,\n",
    "    'w',\n",
    "    driver='GTiff',\n",
    "    height=binary_result.shape[1],\n",
    "    width=binary_result.shape[2],\n",
    "    count=1,\n",
    "    dtype=binary_result.dtype,\n",
    "    crs=imagery_meta['crs'],\n",
    "    transform=imagery_meta['transform']\n",
    ") as dst:\n",
    "    dst.write(binary_result[0], 1)\n",
    "\n",
    "print(f\"Results saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize Results\n",
    "\n",
    "Now, let's vectorize the results to create a shapefile of drainage lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from skimage.morphology import skeletonize\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "# Skeletonize the binary result\n",
    "skeleton = skeletonize(binary_result[0] > 0)\n",
    "\n",
    "# Display skeleton\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(skeleton, cmap='gray')\n",
    "plt.title('Skeletonized Result')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Convert to vector lines\n",
    "lines = []\n",
    "\n",
    "# Find all skeleton pixels\n",
    "skeleton_pixels = np.column_stack(np.where(skeleton > 0))\n",
    "\n",
    "# Group pixels into lines\n",
    "if len(skeleton_pixels) > 0:\n",
    "    current_line = [skeleton_pixels[0]]\n",
    "    for i in range(1, len(skeleton_pixels)):\n",
    "        # Check if pixel is adjacent to the last pixel in the line\n",
    "        last_pixel = current_line[-1]\n",
    "        pixel = skeleton_pixels[i]\n",
    "        \n",
    "        if (abs(pixel[0] - last_pixel[0]) <= 1 and\n",
    "            abs(pixel[1] - last_pixel[1]) <= 1):\n",
    "            # Adjacent pixel, add to current line\n",
    "            current_line.append(pixel)\n",
    "        else:\n",
    "            # Not adjacent, start a new line\n",
    "            if len(current_line) > 1:\n",
    "                # Convert pixel coordinates to world coordinates\n",
    "                coords = []\n",
    "                for p in current_line:\n",
    "                    # Convert pixel coordinates to world coordinates\n",
    "                    x, y = imagery_meta['transform'] * (p[1], p[0])\n",
    "                    coords.append((x, y))\n",
    "                \n",
    "                # Create line\n",
    "                line = LineString(coords)\n",
    "                \n",
    "                # Simplify line\n",
    "                line = line.simplify(1.0)\n",
    "                \n",
    "                # Add to lines\n",
    "                lines.append(line)\n",
    "            \n",
    "            # Start a new line\n",
    "            current_line = [pixel]\n",
    "    \n",
    "    # Add the last line\n",
    "    if len(current_line) > 1:\n",
    "        # Convert pixel coordinates to world coordinates\n",
    "        coords = []\n",
    "        for p in current_line:\n",
    "            # Convert pixel coordinates to world coordinates\n",
    "            x, y = imagery_meta['transform'] * (p[1], p[0])\n",
    "            coords.append((x, y))\n",
    "        \n",
    "        # Create line\n",
    "        line = LineString(coords)\n",
    "        \n",
    "        # Simplify line\n",
    "        line = line.simplify(1.0)\n",
    "        \n",
    "        # Add to lines\n",
    "        lines.append(line)\n",
    "\n",
    "# Create GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    {\"geometry\": lines},\n",
    "    crs=imagery_meta['crs']\n",
    ")\n",
    "\n",
    "# Save to shapefile\n",
    "output_shapefile = '../data/results/drainage_lines.shp'\n",
    "gdf.to_file(output_shapefile)\n",
    "\n",
    "print(f\"Vectorized results saved to {output_shapefile}\")\n",
    "print(f\"Number of drainage lines: {len(lines)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results\n",
    "\n",
    "Finally, let's visualize the results overlaid on the original imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the shapefile\n",
    "drainage_lines = gpd.read_file(output_shapefile)\n",
    "\n",
    "# Create a figure\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "# Display the satellite imagery\n",
    "show(imagery, transform=imagery_meta['transform'], ax=ax)\n",
    "\n",
    "# Display the drainage lines\n",
    "drainage_lines.plot(ax=ax, color='red', linewidth=2)\n",
    "\n",
    "# Set title and turn off axis\n",
    "ax.set_title('Detected Drainage Lines')\n",
    "ax.set_axis_off()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we've demonstrated how to use the DrainageAI system to detect drainage pipes in satellite imagery. We've covered the following steps:\n",
    "\n",
    "1. Loading and preprocessing satellite imagery and elevation data\n",
    "2. Running inference with the DrainageAI model\n",
    "3. Saving the results as a GeoTIFF file\n",
    "4. Vectorizing the results to create a shapefile of drainage lines\n",
    "5. Visualizing the results overlaid on the original imagery\n",
    "\n",
    "This workflow can be applied to any satellite imagery to detect drainage pipes in agricultural fields."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
