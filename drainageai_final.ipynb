{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DrainageAI Workflow\n",
    "\n",
    "Complete workflow for DrainageAI: setup, indices calculation, BYOL training, and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from google.colab import files\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "!pip install rasterio geopandas scikit-image matplotlib tqdm\n",
    "!mkdir -p data/imagery data/indices results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Upload and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Upload your multispectral imagery file (GeoTIFF format):\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Save uploaded files\n",
    "for filename in uploaded.keys():\n",
    "    with open(f\"data/imagery/{filename}\", 'wb') as f:\n",
    "        f.write(uploaded[filename])\n",
    "    print(f\"Saved {filename} to data/imagery/\")\n",
    "    \n",
    "# Get the first uploaded file\n",
    "imagery_filename = list(uploaded.keys())[0]\n",
    "imagery_path = f\"data/imagery/{imagery_filename}\"\n",
    "\n",
    "# Check image properties\n",
    "with rasterio.open(imagery_path) as src:\n",
    "    num_bands = src.count\n",
    "    height = src.height\n",
    "    width = src.width\n",
    "    \n",
    "print(f\"Image has {num_bands} bands, dimensions: {width}x{height}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculate Spectral Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_indices(imagery_path, output_path, indices=\"ndvi,msavi2\", \n",
    "                     red_band=3, nir_band=4):\n",
    "    print(f\"Calculating spectral indices for {imagery_path}...\")\n",
    "    indices_to_calculate = indices.lower().split(\",\")\n",
    "    \n",
    "    with rasterio.open(imagery_path) as src:\n",
    "        num_bands = src.count\n",
    "        red_band = min(red_band, num_bands)\n",
    "        nir_band = min(nir_band, num_bands) if num_bands >= 4 else red_band\n",
    "        \n",
    "        red = src.read(red_band)\n",
    "        nir = src.read(nir_band)\n",
    "        meta = src.meta.copy()\n",
    "    \n",
    "    calculated_indices = []\n",
    "    band_names = []\n",
    "    \n",
    "    if \"ndvi\" in indices_to_calculate:\n",
    "        ndvi = (nir - red) / (nir + red + 1e-8)\n",
    "        calculated_indices.append(ndvi)\n",
    "        band_names.append(\"NDVI\")\n",
    "    \n",
    "    if \"msavi2\" in indices_to_calculate:\n",
    "        msavi2 = (2 * nir + 1 - np.sqrt((2 * nir + 1)**2 - 8 * (nir - red))) / 2\n",
    "        calculated_indices.append(msavi2)\n",
    "        band_names.append(\"MSAVI2\")\n",
    "    \n",
    "    indices_stack = np.stack(calculated_indices)\n",
    "    meta.update({\n",
    "        'count': len(calculated_indices),\n",
    "        'dtype': 'float32'\n",
    "    })\n",
    "    \n",
    "    with rasterio.open(output_path, 'w', **meta) as dst:\n",
    "        for i, (index, name) in enumerate(zip(calculated_indices, band_names), 1):\n",
    "            dst.write(index.astype(np.float32), i)\n",
    "            dst.set_band_description(i, name)\n",
    "    \n",
    "    print(f\"Indices saved to {output_path}\")\n",
    "    return indices_stack\n",
    "\n",
    "# Calculate indices\n",
    "indices_path = \"data/indices/spectral_indices.tif\"\n",
    "indices = calculate_indices(\n",
    "    imagery_path=imagery_path,\n",
    "    output_path=indices_path,\n",
    "    indices=\"ndvi,msavi2\",\n",
    "    red_band=3,\n",
    "    nir_band=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. BYOL Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BYOLProjector(nn.Module):\n",
    "    def __init__(self, in_features, hidden_dim=4096, out_dim=256):\n",
    "        super(BYOLProjector, self).__init__()\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(in_features, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.projection(x)\n",
    "\n",
    "class BYOLPredictor(nn.Module):\n",
    "    def __init__(self, in_dim=256, hidden_dim=4096, out_dim=256):\n",
    "        super(BYOLPredictor, self).__init__()\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.predictor(x)\n",
    "\n",
    "class BYOLModel(nn.Module):\n",
    "    def __init__(self, pretrained=True, with_indices=True, momentum=0.99):\n",
    "        super(BYOLModel, self).__init__()\n",
    "        \n",
    "        self.online_encoder = models.resnet50(pretrained=pretrained)\n",
    "        \n",
    "        if with_indices:\n",
    "            first_conv = self.online_encoder.conv1\n",
    "            new_conv = nn.Conv2d(\n",
    "                in_channels=3 + 2,  # RGB + 2 indices\n",
    "                out_channels=64,\n",
    "                kernel_size=7,\n",
    "                stride=2,\n",
    "                padding=3,\n",
    "                bias=False\n",
    "            )\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                new_conv.weight[:, :3] = first_conv.weight\n",
    "                nn.init.kaiming_normal_(\n",
    "                    new_conv.weight[:, 3:],\n",
    "                    mode='fan_out',\n",
    "                    nonlinearity='relu'\n",
    "                )\n",
    "            \n",
    "            self.online_encoder.conv1 = new_conv\n",
    "        \n",
    "        self.online_encoder = nn.Sequential(*list(self.online_encoder.children())[:-1])\n",
    "        self.online_projector = BYOLProjector(2048)\n",
    "        self.predictor = BYOLPredictor()\n",
    "        self.target_encoder = copy.deepcopy(self.online_encoder)\n",
    "        self.target_projector = copy.deepcopy(self.online_projector)\n",
    "        \n",
    "        for param in self.target_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.target_projector.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        self.momentum = momentum\n",
    "        self.prediction_head = nn.Sequential(\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.fine_tuned = False\n",
    "        self.with_indices = with_indices\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.online_encoder(x)\n",
    "        features = torch.flatten(features, 1)\n",
    "        if self.fine_tuned:\n",
    "            return self.prediction_head(features)\n",
    "        return features\n",
    "    \n",
    "    def byol_forward(self, x):\n",
    "        online_features = self.online_encoder(x)\n",
    "        online_features = torch.flatten(online_features, 1)\n",
    "        online_proj = self.online_projector(online_features)\n",
    "        online_pred = self.predictor(online_proj)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            target_features = self.target_encoder(x)\n",
    "            target_features = torch.flatten(target_features, 1)\n",
    "            target_proj = self.target_projector(target_features)\n",
    "        \n",
    "        return online_pred, target_proj, online_features\n",
    "    \n",
    "    def byol_loss(self, view1, view2):\n",
    "        online_pred1, target_proj2, online_feat1 = self.byol_forward(view1)\n",
    "        online_pred2, target_proj1, online_feat2 = self.byol_forward(view2)\n",
    "        \n",
    "        online_pred1 = F.normalize(online_pred1, dim=-1)\n",
    "        online_pred2 = F.normalize(online_pred2, dim=-1)\n",
    "        target_proj1 = F.normalize(target_proj1, dim=-1)\n",
    "        target_proj2 = F.normalize(target_proj2, dim=-1)\n",
    "        \n",
    "        loss1 = 2 - 2 * (online_pred1 * target_proj2).sum(dim=-1).mean()\n",
    "        loss2 = 2 - 2 * (online_pred2 * target_proj1).sum(dim=-1).mean()\n",
    "        \n",
    "        loss = (loss1 + loss2) / 2\n",
    "        return loss, (online_feat1 + online_feat2) / 2\n",
    "    \n",
    "    def update_target_network(self):\n",
    "        for online_params, target_params in zip(\n",
    "            self.online_encoder.parameters(), self.target_encoder.parameters()\n",
    "        ):\n",
    "            target_params.data = self.momentum * target_params.data + \\\n",
    "                                (1 - self.momentum) * online_params.data\n",
    "        \n",
    "        for online_params, target_params in zip(\n",
    "            self.online_projector.parameters(), self.target_projector.parameters()\n",
    "        ):\n",
    "            target_params.data = self.momentum * target_params.data + \\\n",
    "                                (1 - self.momentum) * online_params.data\n",
    "    \n",
    "    def save(self, path):\n",
    "        torch.save({\n",
    "            'online_encoder': self.online_encoder.state_dict(),\n",
    "            'online_projector': self.online_projector.state_dict(),\n",
    "            'predictor': self.predictor.state_dict(),\n",
    "            'target_encoder': self.target_encoder.state_dict(),\n",
    "            'target_projector': self.target_projector.state_dict(),\n",
    "            'prediction_head': self.prediction_head.state_dict(),\n",
    "            'fine_tuned': self.fine_tuned,\n",
    "            'with_indices': self.with_indices\n",
    "        }, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataset and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiViewDataset(Dataset):\n",
    "    def __init__(self, imagery_paths, indices_paths=None, transform=None):\n",
    "        self.imagery_paths = imagery_paths\n",
    "        self.indices_paths = indices_paths if indices_paths is not None else [None] * len(imagery_paths)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imagery_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        with rasterio.open(self.imagery_paths[idx]) as src:\n",
    "            imagery = src.read()\n",
    "        \n",
    "        indices = None\n",
    "        if self.indices_paths[idx] is not None:\n",
    "            with rasterio.open(self.indices_paths[idx]) as src:\n",
    "                indices = src.read()\n",
    "        \n",
    "        imagery = torch.from_numpy(imagery).float()\n",
    "        if indices is not None:\n",
    "            indices = torch.from_numpy(indices).float()\n",
    "        \n",
    "        if self.transform:\n",
    "            imagery_view1 = self.transform(imagery)\n",
    "            imagery_view2 = self.transform(imagery)\n",
    "            \n",
    "            if indices is not None:\n",
    "                indices_view1 = self.transform(indices)\n",
    "                indices_view2 = self.transform(indices)\n",
    "                \n",
    "                view1 = torch.cat([imagery_view1, indices_view1], dim=0)\n",
    "                view2 = torch.cat([imagery_view2, indices_view2], dim=0)\n",
    "            else:\n",
    "                view1 = imagery_view1\n",
    "                view2 = imagery_view2\n",
    "        else:\n",
    "            if indices is not None:\n",
    "                view1 = view2 = torch.cat([imagery, indices], dim=0)\n",
    "            else:\n",
    "                view1 = view2 = imagery\n",
    "        \n",
    "        return view1, view2\n",
    "\n",
    "# Define augmentations\n",
    "class RandomAugmentation:\n",
    "    def __call__(self, x):\n",
    "        # Random horizontal flip\n",
    "        if random.random() > 0.5:\n",
    "            x = torch.flip(x, [2])\n",
    "        # Random vertical flip\n",
    "        if random.random() > 0.5:\n",
    "            x = torch.flip(x, [1])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset and data loader\n",
    "transform = RandomAugmentation()\n",
    "dataset = MultiViewDataset(\n",
    "    imagery_paths=[imagery_path],\n",
    "    indices_paths=[indices_path],\n",
    "    transform=transform\n",
    ")\n",
    "data_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Initialize model and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = BYOLModel(pretrained=True, with_indices=True).to(device)\n",
    "optimizer = optim.Adam(\n",
    "    list(model.online_encoder.parameters()) +\n",
    "    list(model.online_projector.parameters()) +\n",
    "    list(model.predictor.parameters()),\n",
    "    lr=0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model.train()\n",
    "epochs = 5  # Reduced for demonstration\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0.0\n",
    "    pbar = tqdm(data_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "    \n",
    "    for batch in pbar:\n",
    "        view1, view2 = batch\n",
    "        view1 = view1.to(device)\n",
    "        view2 = view2.to(device)\n",
    "        \n",
    "        loss, _ = model.byol_loss(view1, view2)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        model.update_target_network()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        pbar.set_postfix({\"Loss\": loss.item()})\n",
    "    \n",
    "    avg_loss = epoch_loss / len(data_loader)\n",
    "    losses.append(avg_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Save model\n",
    "model.save(\"results/byol_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inference and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(model, imagery_path, indices_path, output_path):\n",
    "    model.eval()\n",
    "    \n",
    "    # Load imagery and indices\n",
    "    with rasterio.open(imagery_path) as src:\n",
    "        imagery = src.read()\n",
    "        meta = src.meta.copy()\n",
    "    \n",
    "    with rasterio.open(indices_path) as src:\n",
    "        indices = src.read()\n",
    "    \n",
    "    # Convert to torch tensors\n",
    "    imagery = torch.from_numpy(imagery).float().unsqueeze(0).to(device)\n",
    "    indices = torch.from_numpy(indices).float().unsqueeze(0).to(device)\n",
    "    \n",
    "    # Combine imagery and indices\n",
    "    x = torch.cat([imagery, indices], dim=1)\n",
    "    \n",
    "    # Extract features\n",
    "    with torch.no_grad():\n",
    "        features = model(x)\n",
    "    \n",
    "    # Convert to numpy\n",
    "    features = features.cpu().numpy()[0]\n",
    "    \n",
    "    # Save features\n",
    "    np.save(output_path, features)\n",
    "    \n",
    "    print(f\"Inference completed. Results saved to {output_path}\")\n",
    "    return features\n",
    "\n",
    "# Run inference\n",
    "output_path = \"results/drainage_features.npy\"\n",
    "features = run_inference(model, imagery_path, indices_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "with rasterio.open(imagery_path) as src:\n",
    "    rgb = src.read([1, 2, 3])\n",
    "    rgb = np.transpose(rgb, (1, 2, 0))\n",
    "    rgb = rgb / rgb.max()\n",
    "\n",
    "with rasterio.open(indices_path) as src:\n",
    "    ndvi = src.read(1)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(rgb)\n",
    "plt.title(\"RGB Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(ndvi, cmap='RdYlGn')\n",
    "plt.title(\"NDVI\")\n",
    "plt.colorbar(shrink=0.5)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"results/visualization.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
