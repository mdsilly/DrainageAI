{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DrainageAI Streamlined Workflow\n",
    "\n",
    "Complete workflow for DrainageAI: environment setup, data preparation, spectral indices calculation, BYOL model training, and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import rasterio\n",
    "from google.colab import files\n",
    "\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rasterio geopandas scikit-image matplotlib pytorch-lightning torch-geometric tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data/unlabeled/imagery\n",
    "!mkdir -p data/labeled/imagery\n",
    "!mkdir -p data/labeled/labels\n",
    "!mkdir -p results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Required Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocessing_utils.py\n",
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "def calculate_indices(imagery_path, output_path, indices=\"ndvi,ndmi,msavi2\", \n",
    "                     red_band=3, nir_band=4, swir_band=5, green_band=2, l_param=0.5):\n",
    "    print(f\"Calculating spectral indices for {imagery_path}...\")\n",
    "    indices_to_calculate = indices.lower().split(\",\")\n",
    "    \n",
    "    with rasterio.open(imagery_path) as src:\n",
    "        num_bands = src.count\n",
    "        red_band = min(red_band, num_bands)\n",
    "        nir_band = min(nir_band, num_bands) if num_bands >= 4 else red_band\n",
    "        green_band = min(green_band, num_bands)\n",
    "        swir_band = min(swir_band, num_bands) if num_bands >= 5 else None\n",
    "        \n",
    "        red = src.read(red_band)\n",
    "        nir = src.read(nir_band)\n",
    "        green = src.read(green_band) if \"ndwi\" in indices_to_calculate else None\n",
    "        swir = src.read(swir_band) if \"ndmi\" in indices_to_calculate and swir_band is not None else None\n",
    "        meta = src.meta.copy()\n",
    "    \n",
    "    calculated_indices = []\n",
    "    band_names = []\n",
    "    \n",
    "    if \"ndvi\" in indices_to_calculate:\n",
    "        ndvi = (nir - red) / (nir + red + 1e-8)\n",
    "        calculated_indices.append(ndvi)\n",
    "        band_names.append(\"NDVI\")\n",
    "    \n",
    "    if \"ndmi\" in indices_to_calculate and swir is not None:\n",
    "        ndmi = (nir - swir) / (nir + swir + 1e-8)\n",
    "        calculated_indices.append(ndmi)\n",
    "        band_names.append(\"NDMI\")\n",
    "    \n",
    "    if \"msavi2\" in indices_to_calculate:\n",
    "        msavi2 = (2 * nir + 1 - np.sqrt((2 * nir + 1)**2 - 8 * (nir - red))) / 2\n",
    "        calculated_indices.append(msavi2)\n",
    "        band_names.append(\"MSAVI2\")\n",
    "    \n",
    "    if \"ndwi\" in indices_to_calculate and green is not None:\n",
    "        ndwi = (green - nir) / (green + nir + 1e-8)\n",
    "        calculated_indices.append(ndwi)\n",
    "        band_names.append(\"NDWI\")\n",
    "    \n",
    "    if \"savi\" in indices_to_calculate:\n",
    "        savi = (nir - red) * (1 + l_param) / (nir + red + l_param + 1e-8)\n",
    "        calculated_indices.append(savi)\n",
    "        band_names.append(\"SAVI\")\n",
    "    \n",
    "    if not calculated_indices:\n",
    "        print(\"No indices were calculated.\")\n",
    "        return None\n",
    "    \n",
    "    indices_stack = np.stack(calculated_indices)\n",
    "    meta.update({\n",
    "        'count': len(calculated_indices),\n",
    "        'dtype': 'float32'\n",
    "    })\n",
    "    \n",
    "    with rasterio.open(output_path, 'w', **meta) as dst:\n",
    "        for i, (index, name) in enumerate(zip(calculated_indices, band_names), 1):\n",
    "            dst.write(index.astype(np.float32), i)\n",
    "            dst.set_band_description(i, name)\n",
    "    \n",
    "    print(f\"Indices saved to {output_path}\")\n",
    "    return indices_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile byol_model.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import copy\n",
    "\n",
    "class BYOLProjector(nn.Module):\n",
    "    def __init__(self, in_features, hidden_dim=4096, out_dim=256):\n",
    "        super(BYOLProjector, self).__init__()\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(in_features, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.projection(x)\n",
    "\n",
    "class BYOLPredictor(nn.Module):\n",
    "    def __init__(self, in_dim=256, hidden_dim=4096, out_dim=256):\n",
    "        super(BYOLPredictor, self).__init__()\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.predictor(x)\n",
    "\n",
    "class BYOLModel(nn.Module):\n",
    "    def __init__(self, pretrained=True, with_indices=True, momentum=0.99):\n",
    "        super(BYOLModel, self).__init__()\n",
    "        \n",
    "        self.online_encoder = models.resnet50(pretrained=pretrained)\n",
    "        \n",
    "        if with_indices:\n",
    "            first_conv = self.online_encoder.conv1\n",
    "            new_conv = nn.Conv2d(\n",
    "                in_channels=3 + 3,  # RGB + 3 indices\n",
    "                out_channels=64,\n",
    "                kernel_size=7,\n",
    "                stride=2,\n",
    "                padding=3,\n",
    "                bias=False\n",
    "            )\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                new_conv.weight[:, :3] = first_conv.weight\n",
    "                nn.init.kaiming_normal_(\n",
    "                    new_conv.weight[:, 3:],\n",
    "                    mode='fan_out',\n",
    "                    nonlinearity='relu'\n",
    "                )\n",
    "            \n",
    "            self.online_encoder.conv1 = new_conv\n",
    "        \n",
    "        self.online_encoder = nn.Sequential(*list(self.online_encoder.children())[:-1])\n",
    "        self.online_projector = BYOLProjector(2048)\n",
    "        self.predictor = BYOLPredictor()\n",
    "        self.target_encoder = self._copy_encoder(self.online_encoder)\n",
    "        self.target_projector = self._copy_weights(self.online_projector)\n",
    "        self.momentum = momentum\n",
    "        \n",
    "        self.prediction_head = nn.Sequential(\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.fine_tuned = False\n",
    "        self.with_indices = with_indices\n",
    "        self.confidence_threshold = 0.5\n",
    "    \n",
    "    def _copy_encoder(self, encoder):\n",
    "        target_encoder = copy.deepcopy(encoder)\n",
    "        for param in target_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        return target_encoder\n",
    "    \n",
    "    def _copy_weights(self, model):\n",
    "        target_model = copy.deepcopy(model)\n",
    "        for param in target_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        return target_model\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.fine_tuned:\n",
    "            features = self.online_encoder(x)\n",
    "            features = torch.flatten(features, 1)\n",
    "            return self.prediction_head(features)\n",
    "        else:\n",
    "            features = self.online_encoder(x)\n",
    "            features = torch.flatten(features, 1)\n",
    "            return features\n",
    "    \n",
    "    def byol_forward(self, x):\n",
    "        online_features = self.online_encoder(x)\n",
    "        online_features = torch.flatten(online_features, 1)\n",
    "        online_proj = self.online_projector(online_features)\n",
    "        online_pred = self.predictor(online_proj)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            target_features = self.target_encoder(x)\n",
    "            target_features = torch.flatten(target_features, 1)\n",
    "            target_proj = self.target_projector(target_features)\n",
    "        \n",
    "        return online_pred, target_proj, online_features\n",
    "    \n",
    "    def byol_loss(self, view1, view2):\n",
    "        online_pred1, target_proj2, online_feat1 = self.byol_forward(view1)\n",
    "        online_pred2, target_proj1, online_feat2 = self.byol_forward(view2)\n",
    "        \n",
    "        online_pred1 = F.normalize(online_pred1, dim=-1)\n",
    "        online_pred2 = F.normalize(online_pred2, dim=-1)\n",
    "        target_proj1 = F.normalize(target_proj1, dim=-1)\n",
    "        target_proj2 = F.normalize(target_proj2, dim=-1)\n",
    "        \n",
    "        loss1 = 2 - 2 * (online_pred1 * target_proj2).sum(dim=-1).mean()\n",
    "        loss2 = 2 - 2 * (online_pred2 * target_proj1).sum(dim=-1).mean()\n",
    "        \n",
    "        loss = (loss1 + loss2) / 2\n",
    "        return loss, (online_feat1 + online_feat2) / 2\n",
    "    \n",
    "    def update_target_network(self):\n",
    "        for online_params, target_params in zip(\n",
    "            self.online_encoder.parameters(), self.target_encoder.parameters()\n",
    "        ):\n",
    "            target_params.data = self.momentum * target_params.data + \\\n",
    "                                (1 - self.momentum) * online_params.data\n",
    "        \n",
    "        for online_params, target_params in zip(\n",
    "            self.online_projector.parameters(), self.target_projector.parameters()\n",
    "        ):\n",
    "            target_params.data = self.momentum * target_params.data + \\\n",
    "                                (1 - self.momentum) * online_params.data\n",
    "    \n",
    "    def save(self, path):\n",
    "        torch.save({\n",
    "            'online_encoder': self.online_encoder.state_dict(),\n",
    "            'online_projector': self.online_projector.state_dict(),\n",
    "            'predictor': self.predictor.state_dict(),\n",
    "            'target_encoder': self.target_encoder.state_dict(),\n",
    "            'target_projector': self.target_projector.state_dict(),\n",
    "            'prediction_head': self.prediction_head.state_dict(),\n",
    "            'fine_tuned': self.fine_tuned,\n",
    "            'with_indices': self.with_indices,\n",
    "            'momentum': self.momentum\n",
    "        }, path)\n",
    "        \n",
    "    def load(self, path):\n",
    "        checkpoint = torch.load(path)\n",
    "        self.online_encoder.load_state_dict(checkpoint['online_encoder'])\n",
    "        self.online_projector.load_state_dict(checkpoint['online_projector'])\n",
    "        self.predictor.load_state_dict(checkpoint['predictor'])\n",
    "        self.target_encoder.load_state_dict(checkpoint['target_encoder'])\n",
    "        self.target_projector.load_state_dict(checkpoint['target_projector'])\n",
    "        self.prediction_head.load_state_dict(checkpoint['prediction_head'])\n",
    "        self.fine_tuned = checkpoint['fine_tuned']\n",
    "        self.with_indices = checkpoint.get('with_indices', True)\n",
    "        self.momentum = checkpoint.get('momentum', 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile byol_trainer.py\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import rasterio\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "class MultiViewDataset(Dataset):\n",
    "    def __init__(self, imagery_paths, indices_paths=None, label_paths=None, transform=None):\n",
    "        self.imagery_paths = imagery_paths\n",
    "        self.indices_paths = indices_paths if indices_paths is not None else [None] * len(imagery_paths)\n",
    "        self.label_paths = label_paths if label_paths is not None else [None] * len(imagery_paths)\n",
    "        self.transform = transform\n",
    "        \n",
    "        assert len(self.imagery_paths) == len(self.indices_paths) == len(self.label_paths), \\\n",
    "            \"All path lists must have the same length\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imagery_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        with rasterio.open(self.imagery_paths[idx]) as src:\n",
    "            imagery = src.read()\n",
    "        \n",
    "        indices = None\n",
    "        if self.indices_paths[idx] is not None:\n",
    "            with rasterio.open(self.indices_paths[idx]) as src:\n",
    "                indices = src.read()\n",
    "        \n",
    "        label = None\n",
    "        if self.label_paths[idx] is not None:\n",
    "            with rasterio.open(self.label_paths[idx]) as src:\n",
    "                label = src.read(1)\n",
    "                label = torch.from_numpy(label).float()\n",
    "        \n",
    "        imagery = torch.from_numpy(imagery).float()\n",
    "        if indices is not None:\n",
    "            indices = torch.from_numpy(indices).float()\n",
    "        \n",
    "        if self.transform:\n",
    "            imagery_view1 = self.transform(imagery)\n",
    "            imagery_view2 = self.transform(imagery)\n",
    "            \n",
    "            if indices is not None:\n",
    "                indices_view1 = self.transform(indices)\n",
    "                indices_view2 = self.transform(indices)\n",
    "                \n",
    "                # Combine imagery and indices\n",
    "                view1 = torch.cat([imagery_view1, indices_view1], dim=0)\n",
    "                view2 = torch.cat([imagery_view2, indices_view2], dim=0)\n",
    "            else:\n",
    "                view1 = imagery_view1\n",
    "                view2 = imagery_view2\n",
    "        else:\n",
    "            if indices is not None:\n",
    "                view1 = view2 = torch.cat([imagery, indices], dim=0)\n",
    "            else:\n",
    "                view1 = view2 = imagery\n",
    "        \n",
    "        if label is not None:\n",
    "            return view1, view2, label\n",
    "        else:\n",
    "            return view1, view2\n",
    "\n",
    "class BYOLTrainer:\n",
    "    def __init__(self, model, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.model.to(device)\n",
    "    \n",
    "    def train_byol(self, train_loader, optimizer, epochs=100):\n",
    "        self.model.train()\n",
    "        losses = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0.0\n",
    "            pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "            \n",
    "            for batch in pbar:\n",
    "                batch = [b.to(self.device) if b is not None else None for b in batch]\n",
    "                \n",
    "                if len(batch) == 3:\n",
    "                    view1, view2, _ = batch\n",
    "                else:\n",
    "                    view1, view2 = batch\n",
    "                \n",
    "                loss, _ = self.model.byol_loss(view1, view2)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                self.model.update_target_network()\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "                pbar.set_postfix({\"Loss\": loss.item()})\n",
    "            \n",
    "            avg_loss = epoch_loss / len(train_loader)\n",
    "            losses.append(avg_loss)\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        return losses\n",
    "    \n",
    "    def fine_tune(self, train_loader, val_loader=None, epochs=10, lr=0.0001):\n",
    "        self.model.fine_tuned = True\n",
    "        \n",
    "        for param in self.model.online_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        optimizer = optim.Adam(self.model.prediction_head.parameters(), lr=lr)\n",
    "        criterion = nn.BCELoss()\n",
    "        \n",
    "        train_metrics = []\n",
    "        val_metrics = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            train_loss = 0.0\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "            \n",
    "            pbar = tqdm(train_loader, desc=f\"Fine-tuning {epoch+1}/{epochs}\")\n",
    "            for batch in pbar:\n",
    "                batch = [b.to(self.device) if b is not None else None for b in batch]\n",
    "                \n",
    "                x, _, label = batch\n",
    "                \n",
    "                output = self.model(x)\n",
    "                \n",
    "                loss = criterion(output, label.unsqueeze(1))\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                pbar.set_postfix({\"Loss\": loss.item()})\n",
    "                \n",
    "                preds = (output > 0.5).float().cpu().detach().numpy()\n",
    "                labels = label.cpu().detach().numpy()\n",
    "                all_preds.extend(preds.flatten())\n",
    "                all_labels.extend(labels.flatten())\n",
    "            \n",
    "            avg_loss = train_loss / len(train_loader)\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "                all_labels, all_preds, average='binary', zero_division=0\n",
    "            )\n",
    "            accuracy = accuracy_score(all_labels, all_preds)\n",
    "            \n",
    "            train_metrics.append({\n",
    "                'loss': avg_loss,\n",
    "                'accuracy': accuracy,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1': f1\n",
    "            })\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_loss:.4f}, \"\n",
    "                  f\"Accuracy: {accuracy:.4f}, F1: {f1:.4f}\")\n",
    "            \n",
    "            if val_loader is not None:\n",
    "                val_metrics_epoch = self.evaluate(val_loader)\n",
    "                val_metrics.append(val_metrics_epoch)\n",
    "                \n",
    "                print(f\"Validation - Accuracy: {val_metrics_epoch['accuracy']:.4f}, \"\n",
    "                      f\"F1: {val_metrics_epoch['f1']:.4f}\")\n",
    "        \n",
    "        return train_metrics, val_metrics\n",
    "    \n",
    "    def evaluate(self, data_loader):\n",
    "        self.model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in data_loader:\n",
    "                batch = [b.to(self.device) if b is not None else None for b in batch]\n",
    "                \n",
    "                x, _, label = batch\n",
    "                \n",
    "                output = self.model(x)\n",
    "                \n",
    "                preds = (output > 0.5).float().cpu().numpy()\n",
    "                labels = label.cpu().numpy()\n",
    "                all_preds.extend(preds.flatten())\n",
    "                all_labels.extend(labels.flatten())\n",
    "        \n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            all_labels, all_preds, average='binary', zero_division=0\n",
    "        )\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1\n",
    "        }\n",
    "\n",
    "def find_data_files(directory, extensions):\n",
    "    files = []\n",
    "    for root, _, filenames in os.walk(directory):\n",
    "        for filename in filenames:\n",
    "            if any(filename.endswith(ext) for ext in extensions):\n",
    "                files.append(os.path.join(root, filename))\n",
    "    return files\n",
    "\n",
    "def train_byol_pipeline(\n",
    "    optical_dir,\n",
    "    indices_dir=None,\n",
    "    label_dir=None,\n",
    "    output_dir=\"results\",\n",
    "    num_labeled=5,\n",
    "    pretrained=True,\n",
    "    byol_epochs=50,\n",
    "    finetune_epochs=10,\n",
    "    batch_size=4,\n",
    "    byol_lr=0.0001,\n",
    "    finetune_lr=0.0001,\n",
    "    val_split=0.2,\n",
    "    seed=42\n",
    "):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    optical_files = find_data_files(optical_dir, ['.tif', '.tiff'])\n",
    "    indices_files = find_data_files(indices_dir, ['.tif', '.tiff']) if indices_dir else None\n",
    "    label_files = find_data_files(label_dir, ['.tif', '.tiff']) if label_dir else None\n",
    "    \n",
